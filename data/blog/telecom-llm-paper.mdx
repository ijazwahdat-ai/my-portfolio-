---
title: Adapting LLaMA-2 for Afghan Telecom Customer Support
date: '2025-08-18'
tags: ['LLM', 'Telecom', 'QLoRA', 'AI Research']
draft: false
summary: A deep dive into how I fine-tuned Llama-2 on consumer hardware to answer Afghan Telecom queries with 89% accuracy.
---

# Abstract

The adaptation of Large Language Models (LLMs) to specialized, low-resource domains presents a significant engineering challenge. This project addresses these challenges through the development of a domain-specific conversational agent for **telecommunications customer support in Afghanistan**.

We introduce the first instruction-following dataset for this domain, comprising **1,750 manually validated Q&A pairs**. Leveraging **Quantized Low-Rank Adaptation (QLoRA)**, we demonstrate a resource-efficient methodology for fine-tuning the LLaMA-2-7B model on a single GPU.

## Key Results

- **Model:** Llama-2-7b-chat-hf
- **Technique:** 4-bit Quantization (QLoRA)
- **Accuracy:** Achieved a high mean score of **89.0/100** for factual correctness in human evaluation by telecom experts.
- **Infrastructure:** Trained on Google Colab Pro.

## Conclusion

This research provides a blueprint for applying state-of-the-art AI in Afghanistan, proving that we can build localized, intelligent agents without needing massive infrastructure.

[Link to GitHub Repository](https://github.com/ijazwahdat-ai/YOUR-REPO)